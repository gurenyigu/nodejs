###### * 阻塞模式下，一个线程只能处理一项任务。
######  * 阻塞模式下，多线程往往能提高系统吞吐量。因为一个线程阻塞时还有其他线程在工作。多线程可以让`CPU`资源不被阻塞中的线程浪费。

###### * 非阻塞模式下，这个线程所使用的`CPU`核心利用率永远是`100%`，`I/O`以事件方式通知。
######  * 非阻塞模式下，线程不会被`I/O`阻塞，永远在利用`CPU`。多线程带来的好处仅仅是在多核`CPU`的情况下利用更多的核。(`Nodejs`的单线程也能带来同样的好处)
  
# 阻塞与非阻塞
* 阻塞`I/O`的一个特点是调用后一定要等到系统内核层面完成所有事件操作后，调用结束。
  * 读取磁盘上的一段文件为例，系统内核在完成磁盘寻道，读取数据，复制数据到内存中之后，这才调用结束。期间，阻塞`I/O`造成`CPU`等待I/O，占用`I/O`时间。`CPU`的性能不能充分利用，为了提高性能，内核提供了非阻塞`I/O`。
* 非阻塞I/O会在调用后立即返回。
### CPU时间片
> 分时操作系统是把`CPU`的时间划分成长短基本相同的时间区间,即"时间片"，通过操作系统的管理，把这些时间片依次轮流地分配给各个用户使用.如果某个作业在时间片结束之前,整个任务还没有完成，那么该作业就被暂停下来,放弃`CPU`，等待下一轮循环再继续做.此时`CPU`又分配给另一个作业去使用。由于计算机的处理速度很快，只要时间片的间隔取得适当,那么一个用户作业从用完分配给它的一个时间片到获得下一个`CPU`时间片，中间有所"停顿"，但用户察觉不出来,好像整个系统全由它"独占"似的。

### 引：单线程，异步`I/O`，事件驱动
>  应用程序的请求过程分为两部分：`CPU`运算和`I/O`读写，`CPU`计算速度通常高于磁盘读写速度，这就导致`CPU`运算已经完成，但是不得不等待磁盘`I/O`任务完成之后在继续接下来的任务。
所以I/O才是应用程序的瓶颈所在！(在I/O密集型业务中，假设请求需要`100ms`来完成，其中`99ms`花在`I/O`上。)如果需要优化应用程序，让他能同时处理更多的请求，我们会采用多线程，同时开启上百甚至上千的线程提高我们的请求处理。
但是由于`CPU`核心在一个时刻只能执行一个事件，因此操作系统通过事件切片的方法，让线程可以较为均匀的使用`CPU`资源。但操作系统在内核切换线程的同时也要切换线程上下文，当线程数量过多时，时间会被消耗在切换线程上线文中。所以在高并发时，多线程结构还是无法做到强大的伸缩性。

* `Nodejs`的单线程并不是一般理论的单线程，只是开启了单个线程进行业务处理(CPU运算)，同时开启了其他线程专供处理`I/O`。当一个指令到达主线程，主线程发现`I/O`之后，直接将这个事件传递给`I/O`线程，不等`I/O`结束，只拿到一个返回值，就去处理下面的业务。
###### * 这就是 单线程、异步`I/O`。
* `I/O`操作完成之后呢，`Nodejs`的I/O处理完会有一个回调事件，这个事件会放在一个事件处理队列里头，在进程启动时`node`会创建一个类似于`while(1)`的循环，这个循环的轮寻每一次够会去查看是否有返回事件需要处理。有则处理，没有则下一次轮询。
* 这就是所谓的事件驱动。在`nodejs`中，事件主要来源于网络请求，文件`I/O`等，根据时间的不同对观察者进行了分类。有文件观察者，网络`I/O`观察者。事件驱动是一个典型的生产者/消费者模型。请求到达观察者前，事件循环从观察者进行消费。主线程就可以马不停蹄的只关注业务不再取进行`I/O`等待。

[引用](https://www.zhihu.com/question/19732473)
### 同步、异步、阻塞、非阻塞

* 阻塞`I/O`模型：默认情况下，所有套接子都是阻塞的。先理解这个流程，一个输入操作通常包括两个阶段：
  * 等待数据准备好
  * 从内核向进程复制数据
  
  ![zhihu](https://pic4.zhimg.com/8244d924a12eaf42d61b41718c559bff_b.jpg)
  * 这两个术语的定义：
    * 同步`I/O`操作：导致请求进程阻塞，直到`I/O`操作完成
    * 异步`I/O`操作：不导致请求进程阻塞
  * 阻塞与非阻塞：进程/线程要访问的数据是否就绪，进程/线程是否需要等待
  * 同步与异步  ：访问数据的方式，同步需要主动读写数据，在读写数据的过程中还是会阻塞;异步只需要`I/O`操作完成的通知，并不主动读写数据，由操作系统内核完成数据读写。

[Linux IO模式及 select、poll、epoll详解](https://segmentfault.com/a/1190000003063859)
> 正式因为这两个阶段，linux系统产生了下面五种网络模式的方案。
- 阻塞 I/O（blocking IO）
- 非阻塞 I/O（nonblocking IO）
- I/O 多路复用（ IO multiplexing）
- 信号驱动 I/O（ signal driven IO）
- 异步 I/O（asynchronous IO）

> 当用户发出`read`操作时，如果`kernel`中的数据还没有准备好，那么它并不会`block`用户进程，而是返回一个`error`。(从用户进程的角度讲，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。)用户进程判断结果是一个`error`时，他就知道数据还没有准备好，于是它可以再次发送`read`操作。一旦`kernel`中的数据准备好了，并且收到了用户进程的`system call`，那么它马上就将数据拷贝到用户内存，然后返回。

## `select`
  > 当用户进程调用了`select`，那么整个进程就会`block`，而同时，`kernel`会监视所有`select`负责的`read`，当任何一个`read`中的数据准备好了，`read`就会返回。这个时候用户进程再调用`read`操作，将数据从`kernel`拷贝到用户进程。
  
## `epoll`
  > 用户进程发起`read`操作后，进程就会休眠，直到事件发生将它唤醒。从`kernel`的角度将，当他收到`asynchronous(异步的) read`之后，首先他会立即返回，所以不会对用户进程产生任何`block`。然后`kernel`会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成后，`kernel`会给用户进程发送一个`signal`，告诉它`read`操作完成了。
![](https://pic2.zhimg.com/7d3eb389b7724878bd7e12ebc6dbcdb5_b.jpg)

#### 异步I/O
> 异步式`I/O`就是少了多线程的开销。对操作系统来说，创建一个线程的代价是十分昂贵的，需要给他分配内存、列入调度、同时在线程切换的时候还要执行内存换页，`CPU`的缓存被清空，切换回来的时候还要从内存中读取信息，破坏了数据的局部性。

* 异步非阻塞式`I/O`提交给系统，让系统完成，完成后通过某种方式通知我。这时候系统已经帮我完成`I/O`操作。具体来说就是你那个作为传入参数的的`buffer`的指针所指向的空间已经读到了数据或者你的`buffer`的数据已经写出去了.

* 非阻塞`I/O`就是要通过某种方式不定时的向系统询问我是否可以开始做某个`I/O`轮询，当可以开始后，是要自己完成`I/O`，也就是说还要自己调用一`read`来填充buffer或者`write`来把`buffer`的数据写出出去。

### epoll和aio区别
* `aio`是异步非阻塞的，其实`aio`是用线程池实现了异步`I/O`
* `epoll`，首先它的`fd`(文件描述符)集里每每一个`fd`都是非阻塞的，不管`epoll`，`delect`还是`poll`在调用时阻塞等待`fd`可用，然后`epoll`只是一个异步通知机制，只是在`fd`可用时通知你，并没有做任何`I/O`操作，所以不是传统异步。
